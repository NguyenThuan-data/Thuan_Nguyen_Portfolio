---
# You don't need to edit this file, it's empty on purpose.
# Edit theme's home layout instead if you wanna make some changes
# See: https://jekyllrb.com/docs/themes/#overriding-theme-defaults
layout: single
author_profile: true
toc: true
toc_sticky: true
---
<span style = "font-size: 20px">kia Ora, I'm Thuan Nguyen
I'm a passionate and curious student pursuing a degree that double majors in Data Science, Network and CyberSecurity. I thrive on turning complex problems into easy-approach solutions. My goal is to leverage my skills in Data, Cyber and my love for learning to contribute to meaningful projects.

<span style = "font-size: 20px">Below you'll find a selection of projects I've worked on, including coursework projects and personal projects. Feel free to explore them and get in touch!

<details markdown="1">
<summary><h2 style="display: inline;">Data Science Projects</h2></summary>

### [Project 1: Walmart Sales Analysis](https://github.com/NguyenThuan-data/Walmart_Sales_Analysis)
* Executed a complete data lifecycle, starting with data acquisition from the **Kaggle API**, up to 10,000 records, followed by rigorous cleaning and transformation using a **Python** script.
* Leveraged Python libraries like Pandas and NumPy for intensive data wrangling, including handling missing values, fixing data types, and performing feature engineering to create new columns like **Total Amount** for richer analysis.
* Architected a data pipeline to load around 10,000 rows of cleaned data into a **PostgreSQL** database using **SQLAlchemy**, then authored complex SQL queries to uncover deep insights into sales patterns and customer behavior.
* Successfully identified key performance indicators, including the most profitable product lines, top-performing branches by revenue, and peak shopping hours to inform staffing and inventory decisions.
* **Tech Stack**:  <code>Python</code> <code>Pandas</code> <code>NumPy</code> <code>PostgreSQL</code> <code>SQLAlchemy</code> <code>Kaggle API</code>

### [Project 2: Employee Performance Analysis](https://github.com/NguyenThuan-data/School_Project_2_Employee_Performance_Analysis)
* Analyzed a dataset of **7,000+** employee records across **20+** features to understand patterns and drivers of employee performance in a corporate environment
* Conducted exploratory data analysis **(EDA)** using Python libraries **(pandas, seaborn, matplotlib)** to visualize trends, detect anomalies, and uncover feature relationships
* Performed **data cleaning** by identifying and removing duplicate records, handling missing values, and treating outliers using the IQR method
* **Generated visual insights** through box plots, scatter plots, and correlation heatmaps to identify high-variance performance indicators and anomalies
* Applied **feature engineering** and selection techniques to prepare the dataset for modeling, aiming to support future predictive analysis or HR decision-making
* **Tech Stack**: <code>Python</code> <code>Pandas</code> <code>Seaborn</code> <code>Matplotlib</code>

### [Project 3: Obesity Analysis Project](https://github.com/NguyenThuan-data/School_Project_3_ObesityAnalysis)
* The project aims to investigate the relationship between lifestyle factors and obesity levels.
* The project uses the 'Dataset for estimation of obesity levels based on eating habits and physical condition in individuals from Colombia, Peru and Mexico'.
* The project seeks to answer the question:**What dietary habits and daily living habits are significantly affected obesity levels?**
* **Tech Stack**: <code>Python</code> <code>Pandas</code> <code>Matplotlib</code> <code>Scikit-learn</code>

### [Project 4: Bank Marketing Campaign Analysis](https://github.com/NguyenThuan-data/School_Project_4_Bank_Analysis)
*	Conducted exploratory data analysis **(EDA)** on over **40,000** customer records, **17 attributes**, performing data cleaning, transformation, and feature selection to enhance model performance
*	Authored a **2,500-word** structured report, synthesizing findings, integrating **data visualizations**, and presenting insights in a clear, data-driven narrative
*	Explored **artificial neural networks (ANNs), optimizing multilayer perceptron (MLP)** architectures through cross-validation, and hyperparameter tuning
*	Developed predictive models for bank marketing campaign outcomes using **K-Nearest Neighbors (KNN) and Naïve Bayes (NB)**, evaluating model performance with confusion matrices, and classification reports
*	**Tech Stack**: <code>Python</code> <code>Scikit-learn</code> <code>KNN</code> <code>Naïve Bayes</code> <code>ANNs</code>

### [Project 5: Data Science Salary Estimator](https://github.com/NguyenThuan-data/ds_salary_proj)
* Created a tool that estimates data science salaries to help data scientists negotiate their income when they get a job.
* Using dowloaded dataset that contain over 3000 job descriptions from **Kaggle** (can not scrape from Glassdoor)
* Engineered features from the text of each job description to quantify the value companies put on python, excel, aws, and spark. 
* Optimized **Linear, Lasso, and Random Forest Regressors** using GridsearchCV to reach the best model.
* **Tech Stack**: <code>Python</code> <code>Scikit-learn</code> <code>Pandas</code> <code>Linear Regression</code> <code>Random Forest</code>

### [Project 6: Wellington Transport Road-Works](https://github.com/NguyenThuan-data/Database_schoolPro_1)
* The project for Wellington Transport (WT) involves developing a database to manage details of roads, road-works projects, staff, and contracts within their region.
* The database stores comprehensive information on roads (ID, name, category, length, sub-section hierarchy), locations (ID, name, coordinates), projects (code, name, dates), staff (ID, roles over time), and contracts with external contractors (number, costs, dates, contractor details).
* The project includes the design of the relational database schema, visualized through a physical model ERD (Entity Relationship Diagram) likely created in a tool like **Visual Paradigm**, which shows tables like Location, Road, Project, Staff, Contract, Role, and their relationships.
* This database system is implemented using **SQ**L, with table creation and sample data insertion to track road sub-sections, staff project assignments with roles and timeframes, and contract management, further demonstrated by data retrieval queries.
* **Tech Stack**: <code>SQL</code> <code>Visual Paradigm</code> <code>Database Design</code>

### [Project 7: Car Dataset Analysis](https://github.com/NguyenThuan-data/School_Project_1_Car_Analysis-)
* This project involves a comprehensive exploration and analysis of a car dataset to understand the key factors that influence car pricing, fuel efficiency, and market segmentation.
* The analysis includes data preprocessing, visualizations, statistical summaries, and insights derived from multivariate techniques.
* **Tech Stack**: <code>Python</code> <code>Pandas</code> <code>Matplotlib</code> <code>Seaborn</code>
</details>

<br>

<details markdown="1">
<summary><h2 style="display: inline;">Additional Project</h2></summary>

### [Bouncing Ball Simulation with Spinning Arc](https://github.com/NguyenThuan-data/bouncing_ball/tree/master)
* This project is a simple 2D physics simulation of bouncing balls within a circular boundary, featuring a "Pac-Man-like" spinning arc that allows balls to escape. It's built using Pygame.
* If one ball bounce out of the boundry, two new balls will be spawned inside.
* **Tech Stack**: <code>Python</code> <code>Pygame</code>
</details>
